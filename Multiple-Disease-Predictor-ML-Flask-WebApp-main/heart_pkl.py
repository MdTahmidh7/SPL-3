# -*- coding: utf-8 -*-
"""heart_pkl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e6ndeUetDS_abpIjc1mI_7bs6cUqXD8D
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from scipy.stats import boxcox
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import classification_report, accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Read dataset
df = pd.read_csv('heart_1.csv')
df

# Check for missing values in the dataset
df.isnull().sum().sum()

# Separate features (X) and target (y)
X = df.drop('target', axis=1)  # Drop the target variable
y = df['target']  # Target variable

from sklearn.feature_selection import SelectKBest, chi2
from sklearn.preprocessing import StandardScaler

from sklearn.feature_selection import SelectKBest, mutual_info_classif

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply SelectKBest with mutual_info_classif
selector = SelectKBest(score_func=mutual_info_classif, k=5)  # Select top 5 features
X_new = selector.fit_transform(X_scaled, y)

# Get the names of the selected features
selected_features = X.columns[selector.get_support()]
print(f"Selected features: {selected_features}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)

# Train an ensemble model (e.g., Random Forest)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Evaluate the model
print(classification_report(y_test, y_pred))

import pickle

# Save the model as a .pkl file
with open('random_forest_model.pkl', 'wb') as f:
    pickle.dump(rf_model, f)